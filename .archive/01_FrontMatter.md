# The Cantrip Language Specification

**Section**: Title & Conformance | **Part**: Foundations (Part I)
**Previous**: (Start) | **Next**: [Mathematical Foundations](01_MathFoundations.md)

---

**Version:** 1.3.0
**Date:** October 24, 2025
**Status:** Publication Ready
**Specification Type:** Normative
**Target Audience:** Language implementers, compiler writers, tool developers

---

## Abstract

Cantrip is a systems programming language designed for memory safety, deterministic performance, and AI-assisted development. It achieves these goals through:

- **Lexical Permission System (LPS)**: Compile-time memory safety without garbage collection or borrow checking
- **Explicit Contracts**: Preconditions and postconditions as executable specifications
- **Effect System**: Compile-time tracking of side effects, allocations, and I/O
- **Modal System**: State machines as first-class types with compile-time verification
- **Memory Regions**: Explicit lifetime control with zero-overhead allocation
- **Comptime Metaprogramming**: Compile-time code generation without macros
- **File-Based Modules**: Code organization through file system structure

Cantrip compiles to native code with performance matching C/C++ while providing memory safety guarantees through region-based lifetime management.

**Design Philosophy:**

1. **Explicit over implicit** - All effects, lifetimes, and permissions visible in code
2. **Local reasoning** - Understanding code must minimal global context
3. **Zero abstraction cost** - Safety guarantees without runtime overhead
4. **LLM-friendly** - Predictable patterns for AI code generation
5. **Simple ownership** - No borrow checker complexity
6. **No macros** - Metaprogramming through comptime only for predictability

**Safety Model:**

- **Prevents**: Use-after-free, double-free, memory leaks
- **Provides**: Deterministic deallocation, zero GC pauses
- **Does NOT prevent**: Aliasing bugs, data races (programmer's responsibility)

**Conformance:** An implementation conforms to this specification if and only if it satisfies all normative requirements stated herein.

### Key Words for Requirement Levels

The key words **MUST**, **MUST NOT**, **REQUIRED**, **SHALL**, **SHALL NOT**, **SHOULD**, **SHOULD NOT**,
**RECOMMENDED**, **MAY**, and **OPTIONAL** in this document are to be interpreted as described in
RFC 2119 and RFC 8174 when, and only when, they appear in all capitals.

### Conformance

An implementation conforms to this specification if and only if it satisfies all normative requirements
stated herein. Extensions MUST NOT invalidate any program that is valid under this specification. Diagnostics,
implementation-defined limits, and unspecified behavior MUST be documented.

### Document Conventions

- Code blocks for the language use the fenced code label `cantrip`.
- Grammar productions use `ebnf` fences.
- Mathematical judgments are typeset with standard notation.
- Error identifiers (e.g., `E9001`) are normative and MUST be reported for corresponding violations.

---

**Definition 1.1 (Mathematical Foundations):** This section establishes the mathematical notation, metavariables, and judgment forms used throughout the Cantrip Language Specification to formally describe syntax, typing rules, and operational semantics.

## 1. Notation and Mathematical Foundations

### 1.1 Overview

**Key innovation/purpose:** Provides a formal mathematical foundation for precisely specifying language semantics through standardized notation, judgment forms, and inference rules.

**When to use this section:**

- When reading type rules (T-\* rules in Â§4-Â§10)
- When reading evaluation semantics (E-\* rules in Part X)
- When encountering unfamiliar mathematical notation
- When implementing a type checker or interpreter

**When NOT to use this section:**

- For learning Cantrip syntax (see Â§2 Lexical Structure)
- For practical programming guidance (see Examples sections)
- For implementation strategies (see Part XIII: Tooling)

**Relationship to other features:**

- **All subsequent sections** use the notation defined here
- **Â§2 (Lexical Structure)**: Uses set notation (âˆˆ, âŠ†) for token categories
- **Â§3 (Abstract Syntax)**: Uses BNF notation for syntax definitions
- **Type System (Part II)**: Uses type judgments (Î“ âŠ¢ e : T) extensively
- **Operational Semantics (Part X)**: Uses evaluation judgments (âŸ¨e, ÏƒâŸ© â‡“ âŸ¨v, Ïƒ'âŸ©)
- **Contract System (Part V)**: Uses Hoare triples ({P} e {Q}) and semantic satisfaction (Ïƒ âŠ¨ P)

**Normative status:** This section is INFORMATIVE. It defines notation but does not impose requirements on implementations. The notation is used to precisely specify requirements in later NORMATIVE sections.

### 1.2 Syntax

#### 1.2.1 Concrete Syntax

**Not applicable:** This section defines mathematical notation and metavariables, not Cantrip language syntax. Concrete syntax for Cantrip appears in Â§2 (Lexical Structure) and subsequent feature sections.

#### 1.2.2 Abstract Syntax

**Metavariable Categories:**

The following metavariable conventions are used throughout the specification. Metavariables are placeholders that stand for actual program constructs.

**Program Entity Metavariables:**

```
x, y, z âˆˆ Var          (variables)
f, g, h âˆˆ FunName      (function names)
m, n, o âˆˆ ProcName     (procedure names)
R, S, T âˆˆ RecordName   (record names)
E, F, G âˆˆ EnumName     (enum names)
```

**Type and Expression Metavariables:**

```
T, U, V âˆˆ Type         (types)
e, eâ‚, eâ‚‚ âˆˆ Expr       (expressions)
v, vâ‚, vâ‚‚ âˆˆ Value      (values)
p, pâ‚, pâ‚‚ âˆˆ Pattern    (patterns)
```

**Modal and Effect Metavariables:**

```
@S, @S', @Sâ‚ âˆˆ State   (modal states)
Îµ, Îµâ‚, Îµâ‚‚ âˆˆ Effect     (effects)
Î” âˆˆ Transitions        (state transition relation)
```

**Contract and Assertion Metavariables:**

```
P, Q, R âˆˆ Assertion    (contract assertions)
{P} ... {Q}            (Hoare triple notation)
```

**Context Metavariables:**

```
Î“, Î“' âˆˆ Context        (type contexts: Var â†’ Type)
Î£, Î£' âˆˆ StateContext   (state contexts: modal state tracking)
Î” âˆˆ EffContext         (effect contexts: available effects)
Ïƒ, Ïƒ' âˆˆ Store          (memory stores: Location â†’ Value)
```

**Context Operations:**

- `Î“, x: T` means "context Î“ extended with binding x: T"
- `Ïƒ[â„“ â†¦ v]` means "store Ïƒ updated so location â„“ maps to value v"

**Judgment Form Notation:**

Judgments are formal statements about programs. Each judgment form has a specific meaning:

```
Î“ âŠ¢ e : T                         (expression e has type T in context Î“)
Î“ âŠ¢ e : T@S                       (type T in modal state @S)
Î“ âŠ¢ e : T@S ! Îµ                   (type T, state @S, effect Îµ)
Î“ âŠ¢ e ! Îµ                         (expression e has effect Îµ)
{P} e {Q}                         (Hoare triple: if P holds before e, Q holds after)
Ïƒ âŠ¨ P                             (store Ïƒ satisfies assertion P)
âŸ¨e, ÏƒâŸ© â†’ âŸ¨e', Ïƒ'âŸ©                 (small-step reduction)
âŸ¨e, ÏƒâŸ© â‡“ âŸ¨v, Ïƒ'âŸ©                   (big-step evaluation)
@Sâ‚ â†’â‚˜ @Sâ‚‚                        (state transition via procedure m)
```

**Formal Operators:**

**Set Theory:**

```
âˆˆ       (element of)               x âˆˆ S           "x is an element of set S"
âŠ†       (subset)                   A âŠ† B           "A is a subset of B"
âˆª       (union)                    A âˆª B           "union of sets A and B"
âˆ©       (intersection)             A âˆ© B           "intersection of sets A and B"
âˆ…       (empty set)                Îµ = âˆ…           "effect Îµ is the empty set (pure)"
Ã—       (cartesian product)        A Ã— B           "product of sets A and B"
```

**Logic:**

```
âˆ§       (conjunction)              P âˆ§ Q           "P and Q both hold"
âˆ¨       (disjunction)              P âˆ¨ Q           "P or Q (or both) holds"
Â¬       (negation)                 Â¬P              "P does not hold"
â‡’       (implication)              P â‡’ Q           "if P then Q"
âŸº      (bi-implication)           P âŸº Q           "P if and only if Q"
âˆ€       (universal quantification) âˆ€x. P           "for all x, P holds"
âˆƒ       (existential quantification) âˆƒx. P         "there exists x such that P holds"
```

**Relations:**

```
â†’       (maps to / reduces to)     x â†’ y           "x maps to y" or "x reduces to y"
â‡’       (implies / pipeline)       P â‡’ Q           "P implies Q"
â‡“       (evaluates to)             e â‡“ v           "expression e evaluates to value v"
â‰¡       (equivalence)              eâ‚ â‰¡ eâ‚‚         "eâ‚ and eâ‚‚ are equivalent"
âŠ¢       (entails / proves)         Î“ âŠ¢ e : T       "context Î“ entails e has type T"
âŠ¨       (satisfies / models)       Ïƒ âŠ¨ P           "store Ïƒ satisfies assertion P"
```

**Substitution:**

```
[x â†¦ v]                            (substitution: replace x with v)
e[x â†¦ v]                           (expression e with x replaced by v)
```

**Inference Rule Format:**

```
[Rule-Name]
premiseâ‚    premiseâ‚‚    ...    premiseâ‚™
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
conclusion
```

#### 1.2.3 Basic Examples

**Example 1: Variable in typing environment**

```
Context: Î“ = {x: i32, y: bool, z: str}
Judgment: Î“ âŠ¢ x : i32

Reading: "In a context where x has type i32, y has type bool, and z has type str,
         the variable x has type i32."
```

**Example 2: Set membership**

```
T âˆˆ {i8, i16, i32, i64}

Reading: "Type T is one of the signed integer types i8, i16, i32, or i64."
```

**Example 3: Substitution**

```
Expression: (x + y)[x â†¦ 5]
Result: 5 + y

Reading: "Substitute 5 for x in the expression x + y, yielding 5 + y."
```

**Example 4: Inference rule application**

```
[T-Add]
Î“ âŠ¢ x : i32
Î“ âŠ¢ 1 : i32
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ x + 1 : i32

Reading: "If x has type i32 and 1 has type i32 in context Î“,
         then x + 1 has type i32."
```

### 1.3 Static Semantics

#### 1.3.1 Well-Formedness Rules

**Purpose:** These rules define when mathematical notation is well-formed, not when Cantrip programs are well-typed (that comes in later sections).

**Well-formed contexts:**

```
[WF-Context-Empty]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âˆ… well-formed

[WF-Context-Extend]
Î“ well-formed
x âˆ‰ dom(Î“)
Î“ âŠ¢ T : Type
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“, x: T well-formed
```

**Explanation:** A context is well-formed if it's either empty or built by extending a well-formed context with a fresh variable and a well-formed type.

**Well-formed judgments:**

```
[WF-Typing-Judgment]
Î“ well-formed
e âˆˆ Expr
T âˆˆ Type
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ e : T is a judgment

[WF-Effect-Judgment]
Î“ well-formed
e âˆˆ Expr
Îµ âˆˆ Effect
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ e ! Îµ is a judgment
```

**Explanation:** A typing judgment is well-formed if the context is well-formed, e is an expression, and T is a type. The judgment may or may not be derivable (provable), but it's syntactically valid.

#### 1.3.2 Notational Properties

**Substitution properties:**

```
Property 1.1 (Substitution Well-Defined):
âˆ€e âˆˆ Expr, x âˆˆ Var, v âˆˆ Value. âˆƒ!e' âˆˆ Expr. e' = e[x â†¦ v]

Reading: "For any expression e, variable x, and value v, there exists a unique
         expression e' that is the result of substituting v for x in e."
```

**Context properties:**

```
Property 1.2 (Context Lookup):
âˆ€Î“, x. (x âˆˆ dom(Î“)) â‡’ âˆƒ!T. Î“(x) = T

Reading: "If variable x is in the domain of context Î“, then there exists a unique
         type T such that Î“ maps x to T."
```

**Set properties:**

```
Property 1.3 (Effect Union Commutativity):
âˆ€Îµâ‚, Îµâ‚‚ âˆˆ Effect. Îµâ‚ âˆª Îµâ‚‚ = Îµâ‚‚ âˆª Îµâ‚

Property 1.4 (Effect Union Associativity):
âˆ€Îµâ‚, Îµâ‚‚, Îµâ‚ƒ âˆˆ Effect. (Îµâ‚ âˆª Îµâ‚‚) âˆª Îµâ‚ƒ = Îµâ‚ âˆª (Îµâ‚‚ âˆª Îµâ‚ƒ)
```

#### 1.3.3 Naming Conventions

**In Cantrip source code:**

- Type names: `CamelCase` (e.g., `Point`, `Vec`, `HashMap`)
- Functions: `snake_case` (e.g., `read_file`, `compute_sum`, `is_valid`)
- Constants: `SCREAMING_SNAKE` (e.g., `MAX_SIZE`, `DEFAULT_PORT`, `PI`)
- Type variables: Single uppercase letters (e.g., `T`, `U`, `V`, `K`)
- Lifetimes: Single lowercase letter with leading apostrophe (e.g., `'a`, `'b`)

**In formal rules:**

- Metavariables follow conventions in Â§1.2.2
- Rule names: `[Category-Description]` (e.g., `[T-Add]`, `[E-IfTrue]`, `[WF-Array]`)

**Type syntax shortcuts:**

```
[T]         â‰¡  slice of T (fat pointer)
[T; n]      â‰¡  array of T with length n
T?          â‰¡  Option<T>
T!          â‰¡  Result<T, Error>
```

### 1.4 Dynamic Semantics

**Not applicable:** Mathematical notation has no runtime semantics. This section defines notation used to specify the dynamic semantics of Cantrip programs in later sections.

**Evaluation judgment forms** (defined here, applied in Part X: Operational Semantics):

**Small-step reduction:**

```
âŸ¨e, ÏƒâŸ© â†’ âŸ¨e', Ïƒ'âŸ©

Reading: "Expression e in store Ïƒ reduces in one step to expression e' in store Ïƒ'."
```

**Big-step evaluation:**

```
âŸ¨e, ÏƒâŸ© â‡“ âŸ¨v, Ïƒ'âŸ©

Reading: "Expression e in store Ïƒ evaluates to value v, producing store Ïƒ'."
```

**Example (from Â§38: Operational Semantics):**

```
Evaluation: âŸ¨2 + 3, ÏƒâŸ© â‡“ âŸ¨5, ÏƒâŸ©

Reading: "The expression 2 + 3 evaluates to 5; the store is unchanged."
```

### 1.5 Reading Type Rules: Complete Examples

This subsection demonstrates how the notation defined above appears in actual specification sections. These examples bridge the abstract notation and concrete Cantrip code.

#### 1.5.1 Example 1: Integer Addition (Â§4 Primitives)

**Cantrip code:**

```cantrip
let x: i32 = 10;
let y: i32 = 20;
let z = x + y;
```

**Type rule:**

```
[T-Add]
Î“ âŠ¢ eâ‚ : T
Î“ âŠ¢ eâ‚‚ : T
T âˆˆ {i8, i16, i32, i64, u8, u16, u32, u64, f32, f64}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ eâ‚ + eâ‚‚ : T
```

**Reading this rule:**

- **Î“**: Typing environment (Â§1.2.2), here `{x: i32, y: i32}`
- **âŠ¢**: Typing judgment (Â§1.2.2), reads "entails" or "proves"
- **eâ‚, eâ‚‚**: Expression metavariables (Â§1.2.2), here `x` and `y`
- **T**: Type metavariable (Â§1.2.2), here `i32`
- **âˆˆ**: Set membership (Â§1.2.2)

**Application to code:**

```
Premises:
  {x: i32, y: i32} âŠ¢ x : i32     (variable lookup)
  {x: i32, y: i32} âŠ¢ y : i32     (variable lookup)
  i32 âˆˆ {i8, i16, ..., f64}      (i32 is a numeric type)

Conclusion:
  {x: i32, y: i32} âŠ¢ x + y : i32
```

The type checker uses this rule to determine that `x + y` has type `i32`.

#### 1.5.2 Example 2: Map Call (Â§2.8 Map Types)

**Cantrip code:**

```cantrip
function add(a: i32, b: i32): i32 { a + b }

let result = add(10, 20);
```

**Type rule:**

```
[T-Call]
Î“ âŠ¢ f : map(Tâ‚, ..., Tâ‚™) â†’ U ! Îµ
Î“ âŠ¢ eâ‚ : Tâ‚    ...    Î“ âŠ¢ eâ‚™ : Tâ‚™
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ f(eâ‚, ..., eâ‚™) : U
```

**Reading this rule:**

- **f**: Function name metavariable (Â§1.2.2), here `add`
- **map(Tâ‚, ..., Tâ‚™) â†’ U ! Îµ**: Map type syntax with effect annotation
- **U**: Return type metavariable (Â§1.2.2), here `i32`

**Application to code:**

```
Premises:
  Î“ âŠ¢ add : map(i32, i32) â†’ i32 ! âˆ…  (map signature)
  Î“ âŠ¢ 10 : i32                       (integer literal)
  Î“ âŠ¢ 20 : i32                       (integer literal)

Conclusion:
  Î“ âŠ¢ add(10, 20) : i32
```

#### 1.5.3 Example 3: Evaluation Semantics (Part X)

**Cantrip code:**

```cantrip
let x = 2 + 3;
```

**Evaluation rule:**

```
[E-Add]
âŸ¨eâ‚, ÏƒâŸ© â‡“ âŸ¨nâ‚, Ïƒ'âŸ©
âŸ¨eâ‚‚, Ïƒ'âŸ© â‡“ âŸ¨nâ‚‚, Ïƒ''âŸ©
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âŸ¨eâ‚ + eâ‚‚, ÏƒâŸ© â‡“ âŸ¨nâ‚ + nâ‚‚, Ïƒ''âŸ©
```

**Reading this rule:**

- **âŸ¨e, ÏƒâŸ©**: Configuration with expression `e` and store `Ïƒ` (Â§1.2.2)
- **â‡“**: Big-step evaluation (Â§1.2.2), reads "evaluates to"
- **nâ‚, nâ‚‚**: Integer value metavariables
- **Ïƒ, Ïƒ', Ïƒ''**: Store metavariables (Â§1.2.2) tracking state changes

**Application to code:**

```
Evaluation steps:
  âŸ¨2, ÏƒâŸ© â‡“ âŸ¨2, ÏƒâŸ©                   (literal evaluates to itself)
  âŸ¨3, ÏƒâŸ© â‡“ âŸ¨3, ÏƒâŸ©                   (literal evaluates to itself)
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  âŸ¨2 + 3, ÏƒâŸ© â‡“ âŸ¨5, ÏƒâŸ©               (addition)
```

The evaluator uses this rule to compute that `2 + 3` evaluates to `5`.

#### 1.5.4 Example 4: Modal State Transitions (Â§10 Modals)

**Cantrip code:**

```cantrip
modal File {
    @Closed -> open() -> @Open;
    @Open -> read() -> @Open;
    @Open -> close() -> @Closed;
}

let file: File@Closed = File.new();
let opened: File@Open = file.open();
```

**State transition rule:**

```
[T-Transition]
Î“ âŠ¢ e : modal P@Sâ‚
Sâ‚ â†’â‚˜ Sâ‚‚ âˆˆ transitions(P)
Î“ âŠ¢ m : proc(mut self: modal P@Sâ‚) -> modal P@Sâ‚‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ e.m() : modal P@Sâ‚‚
```

**Reading this rule:**

- **modal P@S**: Modal type in state (Â§1.2.2)
- **â†’â‚˜**: State transition via procedure m (Â§1.2.2)
- **transitions(P)**: Set of valid transitions for modal P

**Application to code:**

```
Premises:
  Î“ âŠ¢ file : File@Closed                          (file in Closed state)
  Closed â†’open Open âˆˆ transitions(File)           (valid transition)
  Î“ âŠ¢ open : proc(mut self: File@Closed) -> File@Open

Conclusion:
  Î“ âŠ¢ file.open() : File@Open
```

#### 1.5.5 Example 5: Contract Verification (Â§17 Contracts)

**Cantrip code:**

```cantrip
function divide(x: i32, y: i32): i32
    must y != 0
    will result == x / y
{
    x / y
}
```

**Contract verification rule:**

```
[Verify-Ensures]
{P âˆ§ requires(f)} body(f) {ensures(f)[result â†¦ returned_value]}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
{P} f(...) {ensures(f)}
```

**Reading this rule:**

- **{P} e {Q}**: Hoare triple (Â§1.2.2)
- **requires(f)**: Precondition of function f (Â§1.2.2)
- **ensures(f)**: Postcondition of function f (Â§1.2.2)
- **[result â†¦ v]**: Substitution (Â§1.2.2), replace `result` with `v`

**Application to code:**

```
Premises:
  Precondition: y != 0
  Body: x / y
  Postcondition: result == x / y

Verification:
  {y != 0} x / y {result == x / y}

If the caller will y != 0, then the function will result == x / y.
```

### 1.6 Cross-References to Notation Usage

The notation defined in this section is used throughout the specification:

- **Â§2 (Lexical Structure)**: Uses set notation (âˆˆ, âŠ†) for token categories
- **Â§3 (Abstract Syntax)**: Defines syntax using BNF with `::=` and `|`
- **Â§4-Â§10 (Type System)**: Uses type judgments `Î“ âŠ¢ e : T` extensively
- **Â§10 (Modals)**: Uses state transition judgments `@Sâ‚ â†’â‚˜ @Sâ‚‚`
- **Â§13-Â§15 (Functions)**: Uses effect judgments `Î“ âŠ¢ e ! Îµ`
- **Â§17 (Contracts)**: Uses Hoare triples `{P} e {Q}` and semantic satisfaction `Ïƒ âŠ¨ P`
- **Part X (Operational Semantics)**: Uses evaluation judgments `âŸ¨e, ÏƒâŸ© â‡“ âŸ¨v, Ïƒ'âŸ©`

---

**Definition 2.1 (Lexical Structure):** The lexical structure defines the syntax of tokensâ€”the smallest elements of Cantrip source textâ€”including identifiers, literals, keywords, operators, and delimiters.

## 2. Lexical Structure

### 2.1 Overview

**Key innovation/purpose:** Defines the atomic elements (tokens) of Cantrip source code, forming the first phase of compilation that transforms character streams into structured token sequences.

**When to use this section:**

- When implementing a lexer/tokenizer
- When defining concrete syntax for new language features
- When understanding character-level source code rules
- When resolving ambiguities in token formation

**When NOT to use this section:**

- For understanding program structure (see Â§3 Abstract Syntax)
- For type system rules (see Part II: Type System)
- For runtime semantics (see Part X: Operational Semantics)
- For practical programming examples (see feature-specific sections)

**Relationship to other features:**

- **Â§3 (Abstract Syntax)**: Tokens are parsed into abstract syntax trees
- **Â§4+ (Type System)**: Type inference assigns types to literal tokens
- **Compilation Pipeline**: Lexical analysis is the first phase
- **Error Reporting (Â§52)**: Lexical errors are the first class of errors detected

**Phase in compilation pipeline:**

```
Source Text â†’ [Lexer] â†’ Token Stream â†’ [Parser] â†’ AST â†’ [Type Checker] â†’ ...
```

**Token categories:**

- **Identifiers**: Names for variables, functions, types (Â§2.2.3)
- **Literals**: Integer, float, boolean, character, string constants (Â§2.2.4)
- **Keywords**: Reserved words with special meaning (Â§2.2.5)
- **Operators**: Symbolic operators (+, -, \*, /, etc.)
- **Delimiters**: Punctuation ({}, [], (), etc.)
- **Comments**: Discarded during tokenization (Â§2.2.2)

**Scope:** This section defines what tokens LOOK LIKE (their lexical form). Type inference and type checking for literals are defined in Â§4 (Primitives) static semantics.

### 2.2 Syntax

#### 2.2.1 Concrete Syntax

**Source Files:**

**Definition 2.2 (Source File):** A Cantrip source file is a sequence of Unicode characters encoded in UTF-8.

**Grammar:**

```ebnf
SourceFile ::= Utf8Bom? Item*
Utf8Bom    ::= #xEF #xBB #xBF
```

**Formal properties:**

- Encoding: UTF-8 (REQUIRED)
- Line endings: LF (`\n`), CRLF (`\r\n`), or CR (`\r`) (all accepted, normalized to LF during lexing)
- Newlines are significant tokens: Newlines are preserved as tokens during lexical analysis (not discarded as whitespace)
- BOM: Optional UTF-8 BOM (U+FEFF) is ignored if present
- File extension: `.cantrip` (RECOMMENDED)
- Maximum file size: Implementation-defined (RECOMMENDED: 1MB)
- Normalization: Unicode normalization form NFC is RECOMMENDED but not required

**Comments:**

**Grammar:**

```ebnf
Comment      ::= LineComment | BlockComment | DocComment | ModuleDoc
LineComment  ::= "//" ~[\n\r]* [\n\r]
BlockComment ::= "/*" (~"*/" | BlockComment)* "*/"
DocComment   ::= "///" ~[\n\r]*
ModuleDoc    ::= "//!" ~[\n\r]*
```

**Semantic rules:**

- Line comments extend from `//` to end of line
- Block comments nest: `/* outer /* inner */ outer */` is valid
- Doc comments (`///`) document the item that follows
- Module docs (`//!`) document the containing module
- Doc comments are preserved for documentation generation
- Non-doc comments are stripped before parsing
- Comments do not affect statement continuation (newlines after comments are significant)

**Identifiers:**

**Definition 2.3 (Identifier):** An identifier is a sequence of characters used to name variables, functions, types, modules, and other program entities.

**Grammar:**

```ebnf
Identifier    ::= IdentStart IdentContinue*
IdentStart    ::= [a-zA-Z_]
IdentContinue ::= [a-zA-Z0-9_]
```

**Restrictions:**

- Cannot be a reserved keyword (Â§2.2.5)
- Cannot start with a digit
- Case-sensitive: `Variable` â‰  `variable`
- Maximum length: Implementation-defined (RECOMMENDED: 255 characters)

**Integer Literals:**

**Grammar:**

```ebnf
IntegerLiteral ::= DecimalLiteral IntegerSuffix?
                 | HexLiteral IntegerSuffix?
                 | BinaryLiteral IntegerSuffix?
                 | OctalLiteral IntegerSuffix?

DecimalLiteral ::= [0-9] [0-9_]*
HexLiteral     ::= "0x" [0-9a-fA-F] [0-9a-fA-F_]*
BinaryLiteral  ::= "0b" [01] [01_]*
OctalLiteral   ::= "0o" [0-7] [0-7_]*

IntegerSuffix  ::= "i8" | "i16" | "i32" | "i64" | "isize"
                 | "u8" | "u16" | "u32" | "u64" | "usize"
```

**Underscore separators:**

- Underscores (`_`) may appear between digits for readability
- Underscores are ignored during value computation
- Cannot appear at the start or end of the literal
- Cannot appear adjacent to the base prefix (`0x`, `0b`, `0o`)

**Floating-Point Literals:**

**Grammar:**

```ebnf
FloatLiteral ::= DecimalLiteral "." DecimalLiteral Exponent? FloatSuffix?
               | DecimalLiteral Exponent FloatSuffix?

Exponent     ::= [eE] [+-]? DecimalLiteral
FloatSuffix  ::= "f32" | "f64"
```

**Boolean Literals:**

**Grammar:**

```ebnf
BooleanLiteral ::= "true" | "false"
```

**Character Literals:**

**Grammar:**

```ebnf
CharLiteral    ::= "'" (EscapeSequence | ~['\\]) "'"
EscapeSequence ::= "\\" [nrt\\'"0]
                 | "\\x" HexDigit HexDigit
                 | "\\u{" HexDigit+ "}"
```

**Escape sequences:**

- `\n` â€” newline (U+000A)
- `\r` â€” carriage return (U+000D)
- `\t` â€” tab (U+0009)
- `\\` â€” backslash (U+005C)
- `\'` â€” single quote (U+0027)
- `\"` â€” double quote (U+0022)
- `\0` â€” null character (U+0000)
- `\xNN` â€” ASCII character (00-7F)
- `\u{N...}` â€” Unicode scalar value (up to 6 hex digits)

**String Literals:**

**Grammar:**

```ebnf
StringLiteral ::= '"' (EscapeSequence | ~["\\])* '"'
```

**String properties:**

- Strings are sequences of Unicode scalar values (not code points or grapheme clusters)
- Escape sequences are processed during lexing
- Multi-line strings are supported (newlines in source â†’ newlines in string)

**Keywords:**

**Definition 2.4 (Keyword):** A keyword is a reserved identifier with special syntactic meaning that cannot be used as an identifier.

**Reserved keywords (MUST NOT be used as identifiers):**

```
abstract    as          async       await       break
by          case        comptime    const       continue
defer       effect      else        enum        exists
false       forall      function    if          import
internal    invariant               let         loop
match       modal       module      move        must
mut         new         none        own         private
procedure   protected   public      record      ref
region      result      select      self        Self
state       static      trait       true        type
uses        var         where       will        with
```

**Contextual keywords (special meaning in specific contexts):**

```
effects     pure
```

**Statement Terminators:**

**Definition 2.5 (Statement Termination):** Cantrip uses newlines as primary statement terminators. Semicolons are optional and may be used to separate multiple statements on a single line.

**Grammar:**

```ebnf
Separator ::= NEWLINE | ";"
Whitespace ::= " " | "\t" | "\r"  (not newline)
```

**Termination Rules:**

- **Primary rule:** A newline terminates a statement unless a continuation rule applies
- **Optional separator:** Semicolons `;` may be used to separate statements on the same line
- **Whitespace:** Spaces, tabs, and carriage returns are discarded (not significant)
- **Newlines:** Newlines are preserved as tokens (significant for statement boundaries)

**Statement Continuation Rules:**

A statement continues across newlines in exactly four cases:

**Rule 1: Unclosed Delimiters**

```
Statement continues when `(`, `[`, or `<` remains unclosed.
```

**Rule 2: Trailing Operator**

```
Statement continues when line ends with a binary or assignment operator.
Binary operators: +, -, *, /, %, **, ==, !=, <, <=, >, >=, &&, ||, &, |, ^, <<, >>, .., ..=, =>
Assignment operators: =, +=, -=, *=, /=, %=, &=, |=, ^=, <<=, >>=
```

**Rule 3: Leading Dot**

```
Statement continues when next line begins with `.` (method/field access).
```

**Rule 4: Leading Pipeline**

```
Statement continues when next line begins with `=>` (pipeline operator).
```

**Formal Continuation Predicate:**

```
is_continuation(current: Token, state: ParserState) -> bool:
    // Rule 1: Unclosed delimiters
    if state.paren_depth > 0 || state.bracket_depth > 0 || state.angle_depth > 0:
        return true

    // Rule 2: Trailing operator
    if state.previous_token in BINARY_OPERATORS âˆª ASSIGNMENT_OPERATORS:
        return true

    // Rule 3: Leading dot
    if state.next_token == DOT:
        return true

    // Rule 4: Leading pipeline
    if state.next_token == PIPELINE:
        return true

    return false
```

**Examples:**

```cantrip
// Simple statements (newline terminates)
let x = 1
let y = 2

// Multiple statements on one line (semicolon separates)
let x = 1; let y = 2

// Rule 1: Unclosed parentheses
let result = calculate(
    arg1,
    arg2
)

// Rule 2: Trailing operator
let total = base +
    modifier +
    bonus

// Rule 3: Leading dot (method chaining)
result
    .validate()
    .process()

// Rule 4: Leading pipeline
let result = input
    => validate
    => transform
```

#### 2.2.2 Abstract Syntax

**Token Abstract Representation:**

Tokens are represented internally by the compiler as tagged unions:

```
Token ::= Identifier(name: String)
        | IntLiteral(value: Integer, suffix: Option<IntegerType>)
        | FloatLiteral(value: Float, suffix: Option<FloatType>)
        | BoolLiteral(value: Boolean)
        | CharLiteral(value: Char)
        | StringLiteral(value: String)
        | Keyword(word: KeywordKind)
        | Operator(op: OperatorKind)
        | Delimiter(delim: DelimiterKind)
        | Newline                               (significant token)
        | Semicolon                             (optional separator)
        | EOF

KeywordKind ::= Function | Procedure | Record | Enum | Modal | ...
OperatorKind ::= Plus | Minus | Star | Slash | ...
DelimiterKind ::= LParen | RParen | LBrace | RBrace | ...

IntegerType ::= I8 | I16 | I32 | I64 | ISize | U8 | U16 | U32 | U64 | USize
FloatType ::= F32 | F64
```

**Key changes from traditional lexers:**

- **Newline is preserved:** Unlike most C-family languages, newlines are not discarded as whitespace
- **Semicolon is optional:** Semicolons are tokens but not required for statement termination
- **Whitespace handling:** Only spaces, tabs, and carriage returns are discarded; newlines are kept

**Token Stream:**

A token stream is a sequence of tokens:

```
TokenStream ::= Token*
```

**Formal properties:**

```
âˆ€ source_text âˆˆ SourceText. âˆƒ! token_stream âˆˆ TokenStream.
    tokenize(source_text) = token_stream

Reading: "For any source text, there exists a unique token stream produced by tokenization."
```

**Token position tracking:**

Each token carries source location metadata:

```
PositionedToken ::= Token Ã— SourcePosition

SourcePosition ::= {
    file: FilePath,
    line: LineNumber,
    column: ColumnNumber,
    offset: ByteOffset
}
```

#### 2.2.3 Basic Examples

**Example 1: Simple function tokenization**

**Source:**

```cantrip
function add(x: i32, y: i32): i32 {
    x + y
}
```

**Token Stream:**

```
Keyword(Function)
Identifier("add")
Delimiter(LParen)
Identifier("x")
Delimiter(Colon)
Identifier("i32")
Delimiter(Comma)
Identifier("y")
Delimiter(Colon)
Identifier("i32")
Delimiter(RParen)
Delimiter(Colon)
Identifier("i32")
Delimiter(LBrace)
Identifier("x")
Operator(Plus)
Identifier("y")
Delimiter(RBrace)
EOF
```

**Observations:**

- Comments are discarded
- Whitespace is not in the token stream
- Keywords are distinct token types
- Identifiers include both variable names (`x`, `y`) and type names (`i32`)

**Example 2: Literal tokenization**

**Source:**

```cantrip
42
0xFF
"hello"
'a'
true
```

**Token Stream:**

```
IntLiteral(42, None)
IntLiteral(255, None)
StringLiteral("hello")
CharLiteral('a')
BoolLiteral(true)
EOF
```

**Example 3: Maximal munch**

**Source:**

```cantrip
x++
0x10
while_loop
42u32
```

**Token Stream:**

```
Identifier("x")
Operator(PlusPlus)
IntLiteral(16, None)
Identifier("while_loop")
IntLiteral(42, Some(U32))
EOF
```

**Explanation:** The lexer always forms the longest possible token (maximal munch principle).

### 2.3 Static Semantics

#### 2.3.1 Well-Formedness Rules

**Reserved Word Rule:**

```
[WF-Reserved]
w âˆˆ Keywords
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
w cannot be used as identifier
```

**Identifier Validity:**

```
[WF-Identifier]
id = IdentStart IdentContinue*
id âˆ‰ Keywords
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
id is a valid identifier
```

**Literal Suffix Validity:**

```
[WF-Int-Suffix]
suffix âˆˆ {i8, i16, i32, i64, isize, u8, u16, u32, u64, usize}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
IntegerLiteral suffix valid

[WF-Float-Suffix]
suffix âˆˆ {f32, f64}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
FloatLiteral suffix valid
```

**Character Escape Validation:**

```
[WF-Escape-Simple]
c âˆˆ {n, r, t, \\, ', ", 0}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\c is valid escape sequence

[WF-Escape-Hex]
0x00 â‰¤ NN â‰¤ 0x7F
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\xNN is valid ASCII escape

[WF-Escape-Unicode]
0x0000 â‰¤ NNNNNN â‰¤ 0x10FFFF
NNNNNN âˆ‰ [0xD800, 0xDFFF]    (surrogate range)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
\u{NNNNNN} is valid Unicode escape
```

**Underscore Separator Validity:**

```
[WF-Underscore]
'_' appears between two digits
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
underscore placement valid
```

#### 2.3.2 Tokenization Rules

**Formal tokenization function:**

```
tokenize: SourceText â†’ TokenStream

tokenize(Îµ) = []
tokenize(ws Â· rest) = tokenize(rest)  where ws âˆˆ Whitespace
tokenize(comment Â· rest) = tokenize(rest)  where comment âˆˆ Comment
tokenize(keyword Â· rest) = Keyword(keyword) :: tokenize(rest)
tokenize(literal Â· rest) = Literal(literal) :: tokenize(rest)
tokenize(identifier Â· rest) = Identifier(identifier) :: tokenize(rest)
```

**Maximal Munch Principle:**

```
Property 2.1 (Maximal Munch):
âˆ€ text âˆˆ SourceText, tokenâ‚, tokenâ‚‚ âˆˆ Token.
    text starts with tokenâ‚ âˆ§
    text starts with tokenâ‚‚ âˆ§
    length(tokenâ‚) > length(tokenâ‚‚)
    â‡’ tokenize(text) begins with tokenâ‚

Reading: "When multiple tokens match, the lexer always chooses the longest match."
```

**Examples:**

```
"0xFF" â†’ IntLiteral(255) NOT IntLiteral(0), Identifier("xFF")
"x++" â†’ Identifier("x"), Operator(PlusPlus) NOT Identifier("x"), Operator(Plus), Operator(Plus)
"while_loop" â†’ Identifier("while_loop") NOT Keyword("while"), Identifier("_loop")
```

#### 2.3.3 Type Properties

**Formal property (identity):**

```
Property 2.2 (Identifier Equality):
âˆ€ x, y âˆˆ Identifier. x = y âŸº string(x) = string(y)

Reading: "Identifiers are compared as exact character sequences.
         No Unicode normalization is performed during comparison."
```

**Value computation semantics:**

```
Property 2.3 (Integer Literal Value):
âŸ¦nâŸ§áµ¢â‚™â‚œ = value of n in base-10
âŸ¦0xNâŸ§áµ¢â‚™â‚œ = value of N in base-16
âŸ¦0bNâŸ§áµ¢â‚™â‚œ = value of N in base-2
âŸ¦0oNâŸ§áµ¢â‚™â‚œ = value of N in base-8

Property 2.4 (Float Literal Value):
âŸ¦dâ‚.dâ‚‚âŸ§_float = dâ‚ + dâ‚‚ Ã— 10^(-|dâ‚‚|)
âŸ¦x eáµâŸ§_float = x Ã— 10^k

Property 2.5 (Boolean Literal Value):
âŸ¦trueâŸ§_bool = âŠ¤
âŸ¦falseâŸ§_bool = âŠ¥
```

### 2.4 Dynamic Semantics

**No special runtime behavior:** Lexical analysis is a compile-time phase only. Tokens do not exist at runtime.

**Tokenization is pure:**

```
Property 2.6 (Deterministic Tokenization):
âˆ€ source âˆˆ SourceText. tokenize(source) = tokenize(source)

Reading: "Tokenization is deterministic and produces the same result every time."
```

**Tokenization never modifies source:**

```
Property 2.7 (No Side Effects):
tokenize: SourceText â†’ TokenStream is a pure function

Reading: "Tokenization has no side effects and does not modify the input."
```

### 2.5 Additional Properties

#### 2.5.1 Ambiguity Resolution

**Maximal munch in action:**

```cantrip
// Example 1: Operators
x++         â†’ [Identifier("x"), PlusPlus]
            NOT [Identifier("x"), Plus, Plus]

// Example 2: Number literals
0x10        â†’ [IntLiteral(16)]
            NOT [IntLiteral(0), Identifier("x10")]

// Example 3: Keywords
while_loop  â†’ [Identifier("while_loop")]
            NOT [Keyword("while"), Identifier("_loop")]

// Example 4: Type suffix
42u32       â†’ [IntLiteral(42, Some(u32))]
            NOT [IntLiteral(42), Identifier("u32")]
```

**Operator precedence:** Resolved in the parser (Â§3), not the lexer. The token `++` is lexically distinct from two `+` tokens.

#### 2.5.2 Error Conditions

**Invalid tokens:**

```cantrip
@symbol     // ERROR E2001: '@' is not a valid token start character
0xFF_       // ERROR E2002: trailing underscore in integer literal
'\xAB'      // ERROR E2003: hex escape exceeds ASCII range (0x7F)
'\u{D800}'  // ERROR E2004: surrogate code point in Unicode escape
let while = 5  // ERROR E2005: 'while' is reserved keyword
```

**Valid lexically but type-incorrect (type errors detected in Â§4):**

```cantrip
let x: u8 = 256        // Lexically valid, type error (overflow)
let y: i32 = 3.14      // Lexically valid, type error (mismatch)
```

### 2.6 Examples and Patterns

#### 2.6.1 Complete Tokenization Example

**Input:**

```cantrip
function add(x: i32, y: i32): i32 {
    x + y  // Simple addition
}
```

**Token Stream:**

```
[
  Keyword("function"),
  Identifier("add"),
  LParen,
  Identifier("x"),
  Colon,
  Identifier("i32"),
  Comma,
  Identifier("y"),
  Colon,
  Identifier("i32"),
  RParen,
  Colon,
  Identifier("i32"),
  LBrace,
  Identifier("x"),
  Plus,
  Identifier("y"),
  RBrace
]
```

**Observations:**

- Comments are discarded
- Whitespace is not in the token stream
- Keywords are distinct token types
- Identifiers include both variable names (`x`, `y`) and type names (`i32`)

#### 2.6.2 Literal Parsing Examples

**Integer literals:**

```cantrip
42          â†’ IntLiteral(42, None)           // No suffix, default i32
42u64       â†’ IntLiteral(42, Some(u64))      // Explicit u64
0xFF        â†’ IntLiteral(255, None)          // Hexadecimal
0b1010      â†’ IntLiteral(10, None)           // Binary
1_000_000   â†’ IntLiteral(1000000, None)      // Underscores ignored
```

**Floating-point literals:**

```cantrip
3.14        â†’ FloatLiteral(3.14, None)       // No suffix, default f64
3.14f32     â†’ FloatLiteral(3.14, Some(f32))  // Explicit f32
1.0e10      â†’ FloatLiteral(1.0e10, None)     // Scientific notation
```

**String and character literals:**

```cantrip
'a'         â†’ CharLiteral('a')               // ASCII character
'\n'        â†’ CharLiteral('\n')              // Escape sequence
'\u{1F600}' â†’ CharLiteral('ğŸ˜€')              // Unicode escape

"hello"     â†’ StringLiteral("hello")
"line 1\nline 2" â†’ StringLiteral("line 1\nline 2")
```

#### 2.6.3 Statement Termination Examples

**Simple statements:**

```cantrip
let x = 10
let y = 20
let z = x + y
```

**Multi-line expressions:**

```cantrip
let result = base_value +
    adjustment_factor *
    scale_factor

let condition = x > 0 &&
    y < 100 &&
    z != 0
```

**Method chaining:**

```cantrip
let result = builder
    .with_capacity(100)
    .with_name("example")
    .build()
```

**Unclosed delimiters:**

```cantrip
let array = [
    1, 2, 3,
    4, 5, 6
]

let result = compute(
    arg1,
    arg2,
    arg3
)
```

---

**Definition 3.1 (Abstract Syntax):** The abstract syntax defines the structure of Cantrip programs as abstract syntax trees (ASTs), independent of concrete textual representation.

## 3. Abstract Syntax

### 3.1 Overview

**Key innovation/purpose:** Provides a mathematical representation of program structure that separates the essence of code (what it means) from its textual surface form (how it's written), enabling precise formal reasoning.

**When to use this section:**

- When understanding how programs are represented internally
- When reading type rules and operational semantics
- When implementing parsers, type checkers, or interpreters
- When formal reasoning about program transformations

**When NOT to use this section:**

- For writing Cantrip code (see concrete syntax in feature sections)
- For understanding token-level details (see Â§2 Lexical Structure)
- For type checking rules (see Part II: Type System)
- For practical programming examples (see feature-specific sections)

**Relationship to other features:**

- **Â§2 (Lexical Structure)**: Tokens are parsed into ASTs
- **Type System (Part II)**: Type rules operate on AST nodes
- **Operational Semantics (Part X)**: Evaluation rules operate on ASTs
- **Contract System (Part V)**: Contracts annotate AST nodes
- **All subsequent sections**: Use abstract syntax as foundation for formal rules

**Why separate abstract from concrete syntax?**

- **Multiple concrete forms**: `x + y` and `(x) + (y)` have different concrete syntax but identical abstract syntax
- **Easier analysis**: Type checking and evaluation operate on ASTs, not strings
- **Formal reasoning**: Mathematical semantics are defined over abstract syntax
- **Implementation**: Compilers work with ASTs internally

**Relationship in compilation:**

```
Â§2 Concrete Syntax â†’ [Parser] â†’ Â§3 Abstract Syntax â†’ [Type Checker] â†’ [Evaluator]
     Token Stream              AST                   Typed AST         Values
```

**Notation:** Abstract syntax uses mathematical notation from Â§1. For example:

- `e ::= x | n | eâ‚ + eâ‚‚` defines expression forms
- Subscripts distinguish multiple instances (eâ‚, eâ‚‚)
- Vertical bar `|` separates alternatives (sum type)

**Reading guide:**

- Â§3.2 defines syntax forms (what can appear in ASTs)
- Â§3.3 defines static semantics (well-formedness rules)
- Â§3.4 defines dynamic semantics (evaluation on ASTs)
- Â§3.5 provides additional properties
- Â§3.6 provides examples connecting concrete to abstract syntax

### 3.2 Syntax

#### 3.2.1 Concrete Syntax

**Not directly applicable:** Abstract syntax is defined mathematically, independent of concrete textual form. For concrete syntax (how to write Cantrip code), see:

- **Â§2 (Lexical Structure)**: Token-level syntax
- **Feature sections (Â§4+)**: Feature-specific concrete syntax

**Purpose of this section:** Define the STRUCTURE of ASTs, not the TEXT that produces them.

**Note:** While concrete syntax varies (with/without parentheses, whitespace, etc.), abstract syntax captures the canonical structure. For example:

```
Concrete: (x + 1) * 2
Concrete: x + 1 * 2     (with operator precedence)
Abstract: BinOp(Mul, BinOp(Add, Var("x"), Lit(1)), Lit(2))  [SAME]
```

#### 3.2.2 Abstract Syntax

**Definition 3.2 (Type Language):** The abstract syntax of types.

```
T ::= i8 | i16 | i32 | i64 | isize          (signed integers)
    | u8 | u16 | u32 | u64 | usize          (unsigned integers)
    | f32 | f64                              (floats)
    | bool                                   (booleans)
    | char                                   (characters)
    | str                                    (string slice)
    | [T; n]                                 (fixed array)
    | [T]                                    (slice)
    | (Tâ‚, ..., Tâ‚™)                          (tuple)
    | map(Tâ‚, ..., Tâ‚™) â†’ U ! Îµ               (map type)
    | own T                                  (owned type)
    | mut T                                  (mutable reference)
    | imm T                                  (immutable reference)
    | T@S                                    (type T in modal state @S)
    | âˆ€Î±. T                                  (polymorphic type)
    | !                                      (never type)
    | record Name                            (record type)
    | modal Name                             (modal type)
    | enum Name                              (enum type)
    | trait Name                             (trait type)
```

**Key observations:**

- Types are stratified: primitives (i32, bool), compounds ([T; n], (Tâ‚, Tâ‚‚)), named types (record Name)
- Modals extend types with state machines (T@S)
- Type parameters support polymorphism (âˆ€Î±. T)
- References use permission wrappers (own, mut, imm)
- Function types distinguish pure functions from procedures

**Definition 3.3 (Expression Language):** The abstract syntax of expressions.

```
e ::= x                                     (variable)
    | v                                     (value)
    | eâ‚ âŠ• eâ‚‚                               (binary operation)
    | eâ‚ => eâ‚‚                              (pipeline operation)
    | if eâ‚ then eâ‚‚ else eâ‚ƒ                (conditional)
    | let x = eâ‚ in eâ‚‚                     (let binding)
    | var x = eâ‚ in eâ‚‚                     (mutable binding)
    | f(eâ‚, ..., eâ‚™)                        (function call)
    | Î»x:T. e                               (lambda abstraction)
    | eâ‚ SEP eâ‚‚                             (sequencing, SEP = newline or semicolon)
    | move e                                (ownership transfer)
    | region r { e }                        (region block)
    | alloc_inâŸ¨râŸ©(e)                        (region allocation)
    | match e { páµ¢ -> eáµ¢ }                  (pattern matching)
    | loop e { eâ‚‚ }                         (conditional loop)
    | loop p in e { eâ‚‚ }                   (iteration loop)
    | loop { e }                            (infinite loop)
    | break                                 (loop exit)
    | continue                              (loop continue)
    | return e                              (early return)
    | contract(P, e, Q)                     (contract annotation)
    | transition(e, S)                      (explicit state transition)
    | comptime { e }                        (compile-time execution)
    | e.f                                   (field access)
    | e[i]                                  (array/slice index)
    | {fâ‚: eâ‚, ..., fâ‚™: eâ‚™}                (record construction)
    | Variant(e)                            (enum construction)

where SEP ::= NEWLINE | ";"                 (statement separator)
```

**Key observations:**

- Variables (`x`) and values (`v`) are base cases
- Operators (arithmetic, logical, comparison) via `âŠ•`
- Control flow (if, match, while, loop)
- Function calls and lambda abstractions
- Record construction and field access
- Blocks and sequencing (SEP = newline or semicolon)
- Statement separators are abstract: both newlines and semicolons map to the same sequencing construct

**Definition 3.4 (Values):** The abstract syntax of values (fully evaluated expressions).

```
v ::= n                                     (integer literal)
    | f                                     (float literal)
    | true | false                          (boolean)
    | 'c'                                   (character literal)
    | "s"                                   (string literal)
    | ()                                    (unit/none)
    | (vâ‚, ..., vâ‚™)                         (tuple value)
    | [vâ‚, ..., vâ‚™]                         (array value)
    | {fâ‚: vâ‚, ..., fâ‚™: vâ‚™}                (record value)
    | Variant(v)                            (enum variant value)
    | Î»x:T. e                               (closure)
    | â„“                                     (location/pointer)
```

**Key observations:**

- Values are a subset of expressions
- Literals, records, tuples, closures are values
- Values are irreducible (cannot evaluate further)
- Memory locations (â„“) represent heap/stack addresses

**Definition 3.5 (Patterns):** The abstract syntax of patterns for destructuring.

```
p ::= x                                     (variable pattern)
    | _                                     (wildcard)
    | n                                     (integer literal)
    | true | false                          (boolean literal)
    | 'c'                                   (character literal)
    | (pâ‚, ..., pâ‚™)                         (tuple pattern)
    | Variant(p)                            (enum pattern)
    | Record { fâ‚: pâ‚, ..., fâ‚™: pâ‚™ }       (record pattern)
    | [pâ‚, ..., pâ‚™]                         (array pattern)
    | p if e                                (guard pattern)
    | p as x                                (binding pattern)
```

**Key observations:**

- Patterns appear in `match`, `let`, and function parameters
- Support wildcard `_`, variables, literals, constructors
- Nested patterns enable deep destructuring
- Guards (`if e`) add boolean conditions to patterns

**Definition 3.6 (Assertions):** The abstract syntax of pre/post-conditions and invariants.

```
P, Q ::= none                               (trivial assertion)
       | eâ‚ = eâ‚‚                            (equality)
       | eâ‚ < eâ‚‚ | eâ‚ â‰¤ eâ‚‚                  (ordering)
       | P âˆ§ Q | P âˆ¨ Q                      (conjunction/disjunction)
       | Â¬P                                 (negation)
       | P â‡’ Q                              (implication)
       | âˆ€x. P                              (universal quantification)
       | âˆƒx. P                              (existential quantification)
       | forall(x in c) { P }               (collection quantification)
       | exists(x in c) { P }               (existential over collection)
       | @old(e)                            (value on entry)
       | result                             (return value)

Function Contracts ::=
    uses Îµ                                 (effect declaration, newline-terminated)
    must P                                 (preconditions, newline-terminated)
    will Q                                 (postconditions, newline-terminated)
```

**Key observations:**

- Contracts are logical assertions using first-order logic
- `@old(e)` refers to value of `e` before function execution
- `result` refers to the return value in postconditions
- Effect annotations (`uses Îµ`) track side effects

**Definition 3.7 (Effects):** The abstract syntax of effect signatures.

```
Îµ ::= âˆ…                                     (pure/no effects)
    | alloc.heap                            (heap allocation)
    | alloc.heap(bytesâ‰¤n)                   (bounded heap)
    | alloc.region                          (region allocation)
    | alloc.stack                           (stack allocation)
    | alloc.temp                            (temporary allocation)
    | alloc.*                               (any allocation)
    | fs.read | fs.write | fs.delete       (filesystem)
    | net.read(d) | net.write               (network, d âˆˆ {inbound, outbound})
    | time.read | time.sleep(durationâ‰¤d)    (time operations)
    | random                                (non-determinism)
    | thread.spawn(countâ‰¤n) | thread.join   (threading)
    | render.draw | render.compute          (rendering)
    | audio.play | input.read               (I/O)
    | panic                                 (divergence)
    | Îµâ‚ âˆª Îµâ‚‚                               (effect union)
    | Îµâ‚ ; Îµâ‚‚                               (effect sequencing)
    | Â¬Îµ                                    (forbidden effect)
    | effects(f)                            (effects of function f)
    | name                                  (named effect reference)
    | _?                                    (effect hole)
```

**Key observations:**

- Effects track side effects and capabilities
- Pure functions have effect `âˆ…`
- Effects form an algebraic structure (union, sequencing)
- Bounded effects (e.g., `alloc.heap(bytesâ‰¤n)`) enable resource analysis

#### 3.2.3 Basic Examples

**Example 1: Simple arithmetic expression**

**Concrete:**

```cantrip
(x + 1) * 2
```

**Abstract:**

```
BinOp(Mul, BinOp(Add, Var("x"), Lit(1)), Lit(2))
```

**Tree representation:**

```
      Mul
     /   \
   Add    Lit(2)
  /   \
Var("x") Lit(1)
```

**Observation:** Parentheses do not appear in abstract syntaxâ€”they only control parsing.

**Example 2: Function call**

**Concrete:**

```cantrip
add(10, 20)
```

**Abstract:**

```
Call(Var("add"), [Lit(10), Lit(20)])
```

**Example 3: Let binding**

**Concrete:**

```cantrip
let x = 5 in x + 1
```

**Abstract:**

```
Let("x", Lit(5), BinOp(Add, Var("x"), Lit(1)))
```

**Example 4: Pattern match**

**Concrete:**

```cantrip
match result {
    Result.Ok(value) -> process(value),
    Result.Err(e) -> handle_error(e),
}
```

**Abstract:**

```
Match(
    Var("result"),
    [
        Arm(EnumPattern("Result", "Ok", [VarPattern("value")]),
            None,
            Call(Var("process"), [Var("value")])),
        Arm(EnumPattern("Result", "Err", [VarPattern("e")]),
            None,
            Call(Var("handle_error"), [Var("e")]))
    ]
)
```

### 3.3 Static Semantics

#### 3.3.1 Well-Formed Types

**Purpose:** Not all syntactically valid type expressions are well-formed. These rules define type well-formedness (not type-correctnessâ€”that's in later sections).

**Primitive types:**

```
[WF-Int]
T âˆˆ {i8, i16, i32, i64, isize, u8, u16, u32, u64, usize}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ T : Type

[WF-Float]
T âˆˆ {f32, f64}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ T : Type

[WF-Bool]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ bool : Type

[WF-Char]
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ char : Type
```

**Compound types:**

```
[WF-Array]
Î“ âŠ¢ T : Type    n > 0
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ [T; n] : Type

[WF-Slice]
Î“ âŠ¢ T : Type
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ [T] : Type

[WF-Tuple]
Î“ âŠ¢ Tâ‚ : Type    ...    Î“ âŠ¢ Tâ‚™ : Type
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ (Tâ‚, ..., Tâ‚™) : Type
```

**Function types:**

```
[WF-Function]
Î“ âŠ¢ Tâ‚ : Type    ...    Î“ âŠ¢ Tâ‚™ : Type    Î“ âŠ¢ U : Type
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ map(Tâ‚, ..., Tâ‚™) â†’ U : Type

[WF-Procedure]
Î“ âŠ¢ Tâ‚ : Type    ...    Î“ âŠ¢ Tâ‚™ : Type    Î“ âŠ¢ U : Type
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ proc(SelfPerm, Tâ‚, ..., Tâ‚™): U : Type
```

**Modal types:**

```
[WF-Modal]
modal P { ... } well-formed (see Â§10)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ modal P : Type

[WF-Modal-At-State]
Î“ âŠ¢ T : Type    S âˆˆ states(T)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ T@S : Type
```

**Polymorphic types:**

```
[WF-Forall]
Î“, Î± : Type âŠ¢ T : Type
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ âˆ€Î±. T : Type
```

#### 3.3.2 Well-Formed AST Nodes

**Function declaration:**

```
[WF-Function-Decl]
function f(xâ‚: Tâ‚, ..., xâ‚™: Tâ‚™): U uses Îµ { e }
parameters xâ‚...xâ‚™ are distinct
Î“ âŠ¢ Tâ‚ : Type    ...    Î“ âŠ¢ Tâ‚™ : Type    Î“ âŠ¢ U : Type
effect signature Îµ well-formed
body e is an expression
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
function declaration well-formed
```

**Record declaration:**

```
[WF-Record-Decl]
record R { fâ‚: Tâ‚, ..., fâ‚™: Tâ‚™ }
field names fâ‚...fâ‚™ are distinct
Î“ âŠ¢ Tâ‚ : Type    ...    Î“ âŠ¢ Tâ‚™ : Type
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
record declaration well-formed
```

**Enum declaration:**

```
[WF-Enum-Decl]
enum E { Vâ‚(Tâ‚), ..., Vâ‚™(Tâ‚™) }
variant names Vâ‚...Vâ‚™ are distinct
Î“ âŠ¢ Tâ‚ : Type    ...    Î“ âŠ¢ Tâ‚™ : Type
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
enum declaration well-formed
```

**Modal declaration:**

```
[WF-Modal-Decl]
modal P { states: {sâ‚, ..., sâ‚™}, transitions: Î” }
state names sâ‚...sâ‚™ are distinct
state graph (states, Î”) is connected
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
modal declaration well-formed
```

#### 3.3.3 Pattern Exhaustiveness

**Purpose:** Match expressions must handle all possible values (exhaustiveness).

**Definition:** A set of patterns P = {pâ‚, ..., pâ‚™} is exhaustive for type T if every value v : T matches at least one pattern páµ¢.

**Formal rule:**

```
[WF-Match-Exhaustive]
Î“ âŠ¢ e : T
patterns {pâ‚, ..., pâ‚™} are exhaustive for T
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
match e { pâ‚ -> eâ‚, ..., pâ‚™ -> eâ‚™ } well-formed
```

**Examples:**

```cantrip
// Exhaustive
match b: bool {
    true -> 1,
    false -> 0,
}

// Non-exhaustive (ERROR)
match b: bool {
    true -> 1,
}

// Exhaustive with wildcard
match x: i32 {
    0 -> "zero",
    _ -> "non-zero",
}
```

#### 3.3.4 Scoping Rules

**Variable Binding:**

- `let x = eâ‚ in eâ‚‚` introduces variable `x` in scope of `eâ‚‚`
- Function parameters introduce variables in function body scope
- Pattern matching introduces variables in match arm scope

**Type Parameter Binding:**

- `<T>` on function/record/enum introduces type parameter `T`
- Scope extends to function body / record fields / enum variants

**Shadowing:**

- Inner bindings shadow outer bindings with the same name
- Shadowing is lexically scoped (block-local)

**Example:**

```cantrip
let x = 10           // xâ‚ : i32 = 10
let x = x + 5        // xâ‚‚ : i32 = 15 (shadows xâ‚)
{
    let x = "hello"  // xâ‚ƒ : str = "hello" (shadows xâ‚‚ in this block)
    print(x)         // Prints "hello" (refers to xâ‚ƒ)
}
print(x)             // Prints 15 (refers to xâ‚‚, xâ‚ƒ out of scope)
```

### 3.4 Dynamic Semantics

**Purpose:** Abstract syntax nodes are evaluated at runtime according to operational semantics defined in Part X. This section explains how ASTs relate to evaluation.

**Evaluation operates on ASTs:** All evaluation rules in Part X operate on abstract syntax, not concrete text. For example:

**Evaluation judgment:**

```
âŸ¨e, ÏƒâŸ© â‡“ âŸ¨v, Ïƒ'âŸ©

Where:
- e âˆˆ Expr (abstract expression)
- Ïƒ âˆˆ Store (memory state)
- v âˆˆ Value (result value)
- Ïƒ' âˆˆ Store (updated memory)
```

**Example evaluation rule (from Â§38):**

```
[E-Add]
âŸ¨eâ‚, ÏƒâŸ© â‡“ âŸ¨nâ‚, Ïƒ'âŸ©
âŸ¨eâ‚‚, Ïƒ'âŸ© â‡“ âŸ¨nâ‚‚, Ïƒ''âŸ©
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âŸ¨BinOp(Add, eâ‚, eâ‚‚), ÏƒâŸ© â‡“ âŸ¨nâ‚ + nâ‚‚, Ïƒ''âŸ©
```

**Key observation:** The rule operates on the AST node `BinOp(Add, eâ‚, eâ‚‚)`, not the text "eâ‚ + eâ‚‚".

**Evaluation order:** Specified in Â§41 (Evaluation Order), operates on AST structure.

**No runtime representation:** ASTs are compiled to machine code. The AST structure determines:

- Memory layout (Â§40)
- Evaluation order (Â§41)
- Effect execution (Part VI)
- Contract checking (Part V)

### 3.5 Additional Properties

#### 3.5.1 AST Structure Properties

**Property 3.1 (Unique Parsing):**

```
âˆ€ source âˆˆ ValidSourceText. âˆƒ! ast âˆˆ AST. parse(source) = ast

Reading: "Every valid source text parses to a unique AST."
```

**Property 3.2 (Pretty-Printing Inverse):**

```
âˆ€ ast âˆˆ AST. parse(pretty_print(ast)) â‰¡ ast

Reading: "Parsing the pretty-printed form of an AST yields an equivalent AST."
```

**Property 3.3 (AST Traversal):**

```
âˆ€ ast âˆˆ AST. size(ast) = 1 + Î£(size(child) for child in children(ast))

Reading: "The size of an AST is one plus the sum of sizes of its children."
```

#### 3.5.2 Disambiguation via AST

**Concrete Syntax:**

```cantrip
x + y * z
```

**Ambiguous interpretation 1:** `(x + y) * z`

```
AST: Mul(Add(x, y), z)
```

**Ambiguous interpretation 2:** `x + (y * z)`

```
AST: Add(x, Mul(y, z))
```

The parser resolves this using operator precedence (multiplication before addition), producing interpretation 2. Once in AST form, there is no ambiguityâ€”the structure is explicit.

**All subsequent stages (type checking, optimization, evaluation) operate on the unambiguous AST.**

### 3.6 Examples and Patterns

#### 3.6.1 Function Definition: Concrete to Abstract

**Concrete Syntax:**

```cantrip
function add(x: i32, y: i32): i32 {
    x + y
}
```

**Abstract Syntax:**

```
FunctionDef {
    name: "add",
    params: [(x, i32), (y, i32)],
    return_type: i32,
    effects: âˆ…,
    contracts: none,
    body: BinOp(Add, Var("x"), Var("y"))
}
```

**Tree representation:**

```
FunctionDef
â”œâ”€â”€ name: "add"
â”œâ”€â”€ params: [(x, i32), (y, i32)]
â”œâ”€â”€ return_type: i32
â”œâ”€â”€ effects: âˆ…
â””â”€â”€ body:
    BinOp(Add)
    â”œâ”€â”€ Var("x")
    â””â”€â”€ Var("y")
```

#### 3.6.2 Pattern Matching: Concrete to Abstract

**Concrete Syntax:**

```cantrip
match result {
    Result.Ok(value) -> process(value),
    Result.Err(e) -> handle_error(e),
}
```

**Abstract Syntax:**

```
Match {
    scrutinee: Var("result"),
    arms: [
        Arm {
            pattern: EnumPattern("Result", "Ok", [VarPattern("value")]),
            guard: None,
            body: Call(Var("process"), [Var("value")])
        },
        Arm {
            pattern: EnumPattern("Result", "Err", [VarPattern("e")]),
            guard: None,
            body: Call(Var("handle_error"), [Var("e")])
        }
    ]
}
```

**Tree representation:**

```
Match
â”œâ”€â”€ scrutinee: Var("result")
â””â”€â”€ arms:
    â”œâ”€â”€ Arm
    â”‚   â”œâ”€â”€ pattern: EnumPattern("Result", "Ok", [VarPattern("value")])
    â”‚   â””â”€â”€ body: Call(Var("process"), [Var("value")])
    â””â”€â”€ Arm
        â”œâ”€â”€ pattern: EnumPattern("Result", "Err", [VarPattern("e")])
        â””â”€â”€ body: Call(Var("handle_error"), [Var("e")])
```

#### 3.6.3 Record Construction: Concrete to Abstract

**Concrete Syntax:**

```cantrip
record Point { x: f32, y: f32 }

let p = Point { x: 1.0, y: 2.0 }
```

**Abstract Syntax:**

```
RecordDecl {
    name: "Point",
    fields: [(x, f32), (y, f32)]
}

LetBinding {
    var: "p",
    type: record Point,
    value: RecordConstruct {
        name: "Point",
        fields: [(x, Lit(1.0)), (y, Lit(2.0))]
    }
}
```

#### 3.6.4 Relationship to Formal Semantics

**Type Rules (Part II):** Type checking operates on abstract syntax trees, assigning types to expressions.

**Example:** The type rule for addition operates on abstract syntax:

```
[T-Add]
Î“ âŠ¢ eâ‚ : T
Î“ âŠ¢ eâ‚‚ : T
T âˆˆ {i8, i16, i32, i64, u8, u16, u32, u64, f32, f64}
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ BinOp(Add, eâ‚, eâ‚‚) : T
```

Here `BinOp(Add, eâ‚, eâ‚‚)` refers to the abstract syntax node, not the string "eâ‚ + eâ‚‚". The parser has already transformed the concrete syntax `eâ‚ + eâ‚‚` into the AST node.

**Statement Separators in Type Rules:**

Both newlines and semicolons are treated identically in abstract syntaxâ€”they both represent sequencing. The type rule for sequencing applies uniformly:

```
[T-Seq]
Î“ âŠ¢ eâ‚ : Tâ‚
Î“ âŠ¢ eâ‚‚ : Tâ‚‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Î“ âŠ¢ eâ‚ SEP eâ‚‚ : Tâ‚‚

where SEP = NEWLINE or ";"
```

This means `let x = 1\nlet y = 2` and `let x = 1; let y = 2` have identical abstract syntax and type checking behavior.

**Evaluation Rules (Part X):** Operational semantics evaluates abstract syntax:

```
[E-Add]
âŸ¨eâ‚, ÏƒâŸ© â‡“ âŸ¨nâ‚, Ïƒ'âŸ©
âŸ¨eâ‚‚, Ïƒ'âŸ© â‡“ âŸ¨nâ‚‚, Ïƒ''âŸ©
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
âŸ¨BinOp(Add, eâ‚, eâ‚‚), ÏƒâŸ© â‡“ âŸ¨nâ‚ + nâ‚‚, Ïƒ''âŸ©
```

Again, `BinOp(Add, eâ‚, eâ‚‚)` is the AST node. The evaluation judgment `âŸ¨e, ÏƒâŸ© â‡“ âŸ¨v, Ïƒ'âŸ©` operates on ASTs, not concrete text.

**Why this matters:**

- **Uniformity**: All formal rules reference the same abstract structures
- **Precision**: AST nodes are unambiguous (no parsing issues)
- **Compositionality**: Tree structure enables recursive definitions
- **Implementation**: Compilers transform text â†’ AST once, then work with AST throughout

---

**Definition 4.1 (Attributes):** An attribute is a metadata annotation that modifies the compilation behavior, analysis, or code generation for the item it decorates, evaluated at compile-time without affecting runtime semantics unless explicitly specified.

## 4. Attributes and Annotations

### 4.1 Overview

**Key innovation/purpose:** Attributes provide declarative compiler directives that modify how code is compiled, verified, or represented without changing the code's fundamental logic.

**When to use attributes:**

- Controlling memory layout for FFI interoperability (`[[repr(C)]]`)
- Selecting verification modes (`[[verify(static)]]`, `[[verify(runtime)]]`)
- Configuring runtime behavior (`[[overflow_checks(true)]]`)
- Providing metadata for tools and documentation (`[[module(...)]]`, `[[alias(...)]]`)
- Optimizing compilation (`[[inline]]`, `[[no_mangle]]`)

**When NOT to use attributes:**

- To implement core language behavior (use language features instead)
- As a macro or metaprogramming system (use `comptime` instead)
- To change program logic (attributes modify HOW code compiles, not WHAT it does)
- For runtime configuration (use function parameters or configuration files)

**Relationship to other features:**

- **Contracts (Â§17)**: Attributes can select verification mode for contract checking
- **Effects (Â§21)**: Some attributes affect effect checking
- **Memory Layout (Â§6.5)**: `[[repr(...)]]` controls record/enum layout
- **FFI (Part XIV)**: Attributes critical for C interoperability
- **Metaprogramming (Â§34)**: Attributes are declarative; `comptime` is computational

**Design principle:** Attributes are **declarative compiler hints**, not executable code. They configure the compiler's behavior but don't execute at runtime (unless they change runtime behavior like `[[overflow_checks]]`).

### 4.2 Syntax

#### 4.2.1 Concrete Syntax

**Grammar:**

```ebnf
Attribute      ::= "[[" AttributeBody "]]"
AttributeBody  ::= Ident ( "(" AttrArgs? ")" )?
AttrArgs       ::= AttrArg ( "," AttrArg )*
AttrArg        ::= Ident "=" Literal | Literal | Ident

AttributeList  ::= Attribute+
```

**Syntax:**

```cantrip
// Single attribute
[[repr(C)]]
record Point { x: f32, y: f32 }

// Multiple attributes (stacked)
[[verify(static)]]
[[inline]]
function critical_math(x: i32) { ... }

// Multiple attributes (grouped)
[[repr(C), module(name = "ffi")]]
record CPoint { x: f32, y: f32 }

// Attribute with multiple arguments
[[alias("to_string", "stringify", "as_str")]]
function to_str(x: Debug): String { ... }
```

**Placement rules:**
Attributes appear immediately before the item they modify:

- Module declarations
- Record, enum, modal, trait declarations
- Function and procedure declarations
- Function/procedure parameters
- Record/enum fields
- Type aliases
- Effect declarations

#### 4.2.2 Abstract Syntax

**Formal representation:**

```
Attribute ::= Attr(name: Ident, args: ListâŸ¨AttrArgâŸ©)
AttrArg   ::= Named(key: Ident, value: Literal)
            | Positional(value: Literal)
            | Flag(name: Ident)

Item      ::= item_kind Ã— attrs: ListâŸ¨AttributeâŸ©
```

**Components:**

- **name**: Attribute identifier (e.g., `repr`, `verify`, `module`)
- **args**: List of attribute arguments
  - **Named**: Key-value pairs (`name = "value"`)
  - **Positional**: Just values (`C`, `static`)
  - **Flag**: Just identifiers (`inline`)

**AST representation:**

```
RecordDecl {
    name: "Point",
    fields: [...],
    attributes: [
        Attr("repr", [Positional(Ident("C"))]),
        Attr("module", [Named("name", String("ffi"))])
    ]
}
```

#### 4.2.3 Basic Examples

```cantrip
// Memory layout control
[[repr(C)]]
record Point {
    x: f32,
    y: f32,
}

// Verification mode
[[verify(static)]]
function safe_divide(x: i32, y: i32): i32
    must y != 0
{ x / y }

// Overflow checking
[[overflow_checks(false)]]
function fast_math(x: u32): u32 {
    x * x  // Won't check for overflow even in debug mode
}

// Module metadata
[[module(name = "core", version = "1.0")]]
module math { ... }

// Tooling support
[[alias("to_string", "stringify")]]
public function to_str(x: Debug): String {
    x.debug()
}
```

### 4.3 Static Semantics

#### 4.3.1 Well-Formedness Rules

**Attribute placement validity:**

```
[WF-Attr-Placement]
attr is an attribute
item is a declaration kind
placement(attr) allows item.kind
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
[[attr]] item is well-formed
```

**Attribute argument validation:**

```
[WF-Attr-Args]
attr = Attr(name, args)
âˆ€arg âˆˆ args. signature(attr.name) accepts arg
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
attribute arguments well-formed
```

**No conflicting attributes:**

```
[WF-Attr-No-Conflict]
attrs = list of attributes on item
âˆ€aâ‚, aâ‚‚ âˆˆ attrs. aâ‚ â‰  aâ‚‚ â‡’ Â¬conflicts(aâ‚, aâ‚‚)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
attribute list well-formed
```

**Examples:**

```cantrip
// Valid
[[repr(C)]]
record Point { ... }

// INVALID: repr only applies to records/enums
[[repr(C)]]          // ERROR: repr doesn't apply to functions
function foo() { ... }

// INVALID: conflicting attributes
[[inline]]
[[no_inline]]        // ERROR: inline and no_inline conflict
function bar() { ... }
```

#### 4.3.2 Core Attributes

Cantrip defines the following core attributes. All core attributes are NORMATIVE.

##### 4.3.2.1 `[[repr(...)]]` - Memory Layout Control

**Signature:** `[[repr(layout)]]` where `layout âˆˆ {C, transparent, packed, align(n)}`

**Applies to:** Records, enums

**Semantics:**

```
[Attr-Repr-C]
[[repr(C)]] record R { ... }
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
R uses C-compatible layout (see Â§6.5)

[Attr-Repr-Packed]
[[repr(packed)]] record R { ... }
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
R has no padding between fields
```

**Example:**

```cantrip
// C-compatible layout for FFI
[[repr(C)]]
record Point {
    x: f32,  // offset 0
    y: f32,  // offset 4
}  // total size: 8, alignment: 4

// Packed layout (no padding)
[[repr(packed)]]
record Packed {
    a: u8,   // offset 0
    b: u32,  // offset 1 (no alignment padding!)
}  // total size: 5
```

##### 4.3.2.2 `[[verify(...)]]` - Verification Mode

**Signature:** `[[verify(mode)]]` where `mode âˆˆ {static, runtime, none}`

**Applies to:** Functions, procedures, records (for invariants)

**Semantics:**

```
[Attr-Verify-Static]
[[verify(static)]] function f(...) must P will Q { ... }
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
contracts checked at compile-time via SMT solver

[Attr-Verify-Runtime]
[[verify(runtime)]] function f(...) must P will Q { ... }
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
contracts checked at runtime (assertions injected)

[Attr-Verify-None]
[[verify(none)]] function f(...) must P will Q { ... }
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
contracts are documentation only (no checking)
```

**Example:**

```cantrip
// Static verification (compile-time proof)
[[verify(static)]]
function binary_search(arr: [i32], target: i32): Option<usize>
    must is_sorted(arr)
{ ... }

// Runtime verification (dynamic checks)
[[verify(runtime)]]
function parse_int(s: str): i32
    must !s.is_empty()
    will result >= 0
{ ... }
```

##### 4.3.2.3 `[[overflow_checks(...)]]` - Integer Overflow Behavior

**Signature:** `[[overflow_checks(enabled)]]` where `enabled âˆˆ {true, false}`

**Applies to:** Functions, procedures, blocks

**Semantics:**

```
[Attr-Overflow-Enable]
[[overflow_checks(true)]] function f(...) { ... }
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
all integer operations in f check for overflow (even in release mode)

[Attr-Overflow-Disable]
[[overflow_checks(false)]] function f(...) { ... }
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
no overflow checks in f (wrapping behavior, even in debug mode)
```

**Example:**

```cantrip
// Always check for overflow (safety-critical code)
[[overflow_checks(true)]]
function account_balance(deposits: [u64]): u64 {
    deposits.sum()  // Panics on overflow even in --release
}

// Performance-critical code (wrapping is acceptable)
[[overflow_checks(false)]]
function hash_combine(a: u64, b: u64): u64 {
    a.wrapping_mul(31).wrapping_add(b)
}
```

##### 4.3.2.4 `[[module(...)]]` - Module Metadata

**Signature:** `[[module(key = value, ...)]]`

**Applies to:** Module declarations

**Semantics:** Provides metadata for package management and tooling.

**Common keys:**

- `name`: Module name (string)
- `version`: Semantic version (string)
- `author`: Author information (string)
- `description`: Module description (string)

**Example:**

```cantrip
[[module(
    name = "cantrip.core",
    version = "1.0.0",
    author = "Cantrip Team",
    description = "Core library for Cantrip language"
)]]
module core {
    ...
}
```

##### 4.3.2.5 `[[alias(...)]]` - Alternative Names for Tooling

**Signature:** `[[alias(name1, name2, ...)]]`

**Applies to:** Functions, procedures, types, modules

**Semantics:**
Declares alternative source-level names for an item to improve diagnostics, code search, and LLM tooling. Aliases are INFORMATIVE for tooling and MUST NOT affect name resolution or symbol linkage.

**Normative rules:**

```
[Attr-Alias-Informative]
[[alias(aâ‚, ..., aâ‚™)]] item
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
aliases are accepted in diagnostics and IDE features only
aliases do NOT create new exported symbols

[Attr-Alias-Collision]
[[alias(a)]] itemâ‚
real_name(itemâ‚‚) = a
itemâ‚ â‰  itemâ‚‚
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
emit warning W0101: alias collides with real name
real name wins in all resolution
```

**Example:**

```cantrip
// Provide search-friendly aliases
[[alias("to_string", "stringify", "as_str")]]
public function to_str(x: Debug): String {
    x.debug()
}

// IDE may suggest "to_string" when user types it
// but compiled code always uses "to_str"
```

**For FFI symbol names, use `[[export(...)]]` instead** (see Part XIV: FFI).

##### 4.3.2.6 Other Core Attributes

**`[[inline]]`** - Hint to inline this function
**`[[no_inline]]`** - Prevent inlining
**`[[no_mangle]]`** - Preserve exact symbol name (for FFI)
**`[[deprecated(message)]]`** - Mark as deprecated
**`[[must_use]]`** - Warn if return value is ignored
**`[[cold]]`** - Hint this code is rarely executed
**`[[hot]]`** - Hint this code is performance-critical

These are documented in their respective sections.

#### 4.3.3 User-Defined Attributes

**Status:** User-defined attributes are RESERVED for future versions.

Currently, only core attributes defined in this specification are recognized. User-defined attributes will cause a compilation error:

```cantrip
[[my_custom_attr]]    // ERROR: unknown attribute 'my_custom_attr'
function foo() { ... }
```

**Future design:** User-defined attributes may be added in conjunction with procedural macros or compile-time reflection (see Â§34).

### 4.4 Dynamic Semantics

#### 4.4.1 Compile-Time Processing

Attributes are processed during compilation and do not exist at runtime (with exceptions noted below).

**Processing phases:**

```
Source Code â†’ [Lexer] â†’ [Parser] â†’ AST with Attributes â†’ [Attribute Processing]
                                                                   â†“
                                    [Type Checker] â† Configuration applied
                                          â†“
                                    [Code Generator] â† Layout/optimization directives
```

**Attribute processing order:**

1. **Parsing**: Attributes parsed into AST
2. **Validation**: Well-formedness checking (Â§4.3.1)
3. **Application**: Attributes modify compilation behavior
4. **Erasure**: Most attributes erased after compilation

#### 4.4.2 Attributes Affecting Runtime Behavior

Some attributes change generated code and thus affect runtime:

**`[[overflow_checks(...)]]`:**

- Changes whether overflow checks are emitted
- Affects runtime performance and behavior

**`[[repr(...)]]`:**

- Changes memory layout
- Affects runtime memory usage and access patterns

**`[[inline]]`, `[[no_inline]]`:**

- Change code generation
- Affect runtime performance (but not observable behavior)

**`[[verify(runtime)]]`:**

- Injects runtime assertion checks
- Affects runtime behavior (can panic)

#### 4.4.3 Attributes Not Affecting Runtime

These attributes are purely compile-time metadata:

**`[[verify(static)]]`, `[[verify(none)]]`:**

- Only affect compile-time checking
- No runtime code generated

**`[[alias(...)]]`:**

- Informative only for tooling
- Zero runtime impact

**`[[module(...)]]`:**

- Metadata only
- May appear in debug info but not executable code

#### 4.4.4 Attribute Inheritance

**Attributes do NOT inherit:**

```cantrip
[[inline]]
record Container {
    [[inline]]      // Must explicitly annotate field if desired
    value: i32,
}

[[verify(static)]]
trait Validated {
    // Implementations do NOT automatically get [[verify(static)]]
    function check(self) -> bool;
}
```

Each item must be annotated independently.

### 4.5 Additional Properties

#### 4.5.1 Attribute Conflicts

**Conflicting attributes:**

- `[[inline]]` and `[[no_inline]]`
- `[[repr(C)]]` and `[[repr(packed)]` (use `[[repr(C, packed)]]` instead)

**Conflict detection:**

```
conflicts([[inline]], [[no_inline]]) = true
conflicts([[verify(static)]], [[verify(runtime)]) = true
conflicts([[repr(C)]], [[repr(transparent)]) = true
```

**Error when conflicts detected:**

```cantrip
[[inline]]
[[no_inline]]    // ERROR E4001: conflicting attributes 'inline' and 'no_inline'
function foo() { ... }
```

#### 4.5.2 Unknown Attribute Handling

**Unknown attributes cause compilation errors:**

```cantrip
[[unknown_attr]]    // ERROR E4002: unknown attribute 'unknown_attr'
function bar() { ... }
```

**Rationale:** Explicit errors prevent typos and forward compatibility issues.

**Namespacing:** Future versions may support namespaced attributes: `[[cantrip::core::inline]]`

### 4.6 Examples and Patterns

#### 4.6.1 FFI Data Structure

**Pattern:** C-compatible record layout for foreign function interface.

```cantrip
// Cantrip side (FFI bindings)
[[repr(C)]]
[[module(name = "ffi.sdl")]]
record SDL_Point {
    x: i32,
    y: i32,
}

[[repr(C)]]
record SDL_Rect {
    x: i32,
    y: i32,
    w: i32,
    h: i32,
}

// C side (SDL library)
// typedef struct {
//     int x;
//     int y;
// } SDL_Point;
```

**Explanation:** `[[repr(C)]]` will memory layout matches C exactly, enabling zero-cost FFI.

#### 4.6.2 Safety-Critical Verification

**Pattern:** Static verification for safety-critical code with runtime checks as fallback.

```cantrip
// Statically verified core logic
[[verify(static)]]
function compute_trajectory(
    velocity: Vector3,
    acceleration: Vector3,
    time: f64
): Vector3
    must time >= 0.0
    will result.magnitude() <= velocity.magnitude() + acceleration.magnitude() * time
{
    velocity + acceleration * time
}

// Runtime-verified external input handling
[[verify(runtime)]]
function parse_sensor_data(raw: [u8]): SensorReading
    must raw.len() >= 16
    will result.timestamp > 0
{
    // Parser implementation with runtime checks
    ...
}
```

**Explanation:** Use `[[verify(static)]]` for provably safe internal logic; use `[[verify(runtime)]]` for external input where static proof may be infeasible.

#### 4.6.3 Performance-Critical Tuning

**Pattern:** Fine-tuned optimization hints for hot code paths.

```cantrip
// High-frequency game loop
[[inline]]
[[overflow_checks(false)]]  // Wrapping is safe here
function update_entity_positions(
    entities: [mut Entity],
    delta_time: f32
) {
    for entity in entities {
        // Position wraps around world bounds
        entity.x = entity.x.wrapping_add((entity.vx * delta_time) as u32);
        entity.y = entity.y.wrapping_add((entity.vy * delta_time) as u32);
    }
}

// Rare error path
[[cold]]
function handle_critical_error(error: Error): ! {
    log_error(error);
    std.process.abort();
}
```

**Explanation:** `[[inline]]` reduces function call overhead; `[[overflow_checks(false)]]` eliminates checks where wrapping is intentional; `[[cold]]` tells optimizer this path is rare.

#### 4.6.4 Tooling-Friendly Aliases

**Pattern:** Provide discoverable aliases for common operations.

```cantrip
// Mathematical vector with multiple naming conventions
[[alias("len", "magnitude", "length", "norm")]]
public function size(v: Vector3): f32 {
    (v.x * v.x + v.y * v.y + v.z * v.z).sqrt()
}

// Collection methods with familiar names
[[alias("push_back", "append", "add")]]
public function push(vec: mut Vec<T>, item: T) {
    vec.internal_push(item);
}
```

**Explanation:** LLMs and developers can find functions using familiar terminology, while maintaining canonical naming in actual code.

---
